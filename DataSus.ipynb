{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOagxzA8SFPdqrg5fmgGlJb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Objective of the Project\n",
        "The objective of the project is to be able to open DBC files, the standard format of SINAN, and transform them into a table, converting the encodings according to the data dictionary.\n",
        "\n",
        "It will analyze notifications of accidents involving venomous animals, which are made available by DATASUS through the link https://datasus.saude.gov.br/acesso-a-informacao/doencas-e-agravos-de-notificacao-de-2007-em-diante-sinan/, where there are several databases available.\n",
        "\n",
        "At the end of the project, there will be a data transformation and analysis notebook that can be adapted for other files available from SINAN."
      ],
      "metadata": {
        "id": "qlVMXHOlL4zM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries\n",
        "After installing the library, we need to import the one we will use:\n",
        "*   Pandas: Standard library for data \n",
        "analysis in Python."
      ],
      "metadata": {
        "id": "AqRoCglUONaG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvv46-LW-Iii"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The cell below is necessary to allow us to visualize the entire table on the screen:**"
      ],
      "metadata": {
        "id": "GpnbzwFMPTGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.max_columns = None"
      ],
      "metadata": {
        "id": "E_u3qYhY_qjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Searching for and accessing the project's DBC file.\n",
        "After downloading the DBC file, we will use the TabWin program to transform the data into CSV format, which is more commonly used and easier to work with.\n",
        "\n",
        "The TabWin program can be downloaded from the following link: https://datasus.saude.gov.br/transferencia-de-arquivos/\n",
        "\n",
        "Select:\n",
        "*   Source: Applications - *TABWIN/TABNET* - Tools for data tabulation\n",
        "*   Modality: Programs\n",
        "*   File Type: *TABWIN* data tabulator for Windows\n",
        "\n",
        "Click on **Enviar** (Submit) to upload the file. Once uploaded, click on **Download**. The website will reload, and a link named \"arquivo.zip\" will be downloaded.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "55YIC5ZEPyYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Pandas library will be used to transform the CSV file into a readable table:"
      ],
      "metadata": {
        "id": "UQoNtbVcXD7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas = pd.read_csv('/ANIMBR17.csv', encoding='latin1')"
      ],
      "metadata": {
        "id": "Ssr3xupoAFES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the transformation made, you can use the following command:"
      ],
      "metadata": {
        "id": "7y0mpsHvXgTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas"
      ],
      "metadata": {
        "id": "9gJM1r9bAsii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversion Based on SINAN Data Dictionary\n",
        "In this section, we will define which columns to keep or exclude.\n",
        "\n",
        "For this task, we need to analyze the data dictionary available at the following links:\n",
        "*   Individual Notification Data:  http://portalsinan.saude.gov.br/images/documentos/Agravos/Notificacao_Individual/DIC_DADOS_NET---Notificao-Individual_rev.pdf\n",
        "*   Accidents with Venomous Animals Data:\n",
        "http://portalsinan.saude.gov.br/images/documentos/Agravos/AAP/DIC_DADOS_Animais_Pedonhentos_v5.pdf"
      ],
      "metadata": {
        "id": "5tQEYt5RYD8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the columns of the created table, you can use the command **.columns**"
      ],
      "metadata": {
        "id": "eL32REXlXvUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas.columns"
      ],
      "metadata": {
        "id": "C0a_QiIhAtlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Among the columns above, we need to choose which ones to keep and pass their names to a list."
      ],
      "metadata": {
        "id": "Id-obmShaNi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_maintain =  ['DT_NOTIFIC', 'SEM_NOT', 'NU_ANO', 'SG_UF_NOT',\n",
        "       'ID_MUNICIP', 'ID_REGIONA', 'DT_SIN_PRI', 'SEM_PRI', 'ANO_NASC',\n",
        "       'NU_IDADE_N', 'CS_SEXO', 'CS_GESTANT', 'CS_RACA', 'CS_ESCOL_N', 'SG_UF',\n",
        "       'ID_MN_RESI', 'ID_RG_RESI', 'ID_PAIS', 'DT_INVEST', 'ID_OCUPA_N',\n",
        "       'ANT_DT_ACI', 'ANT_UF', 'ANT_MUNIC_', 'ANT_LOCALI', 'ANT_TEMPO_',\n",
        "       'ANT_LOCA_1', 'MCLI_LOCAL', 'CLI_DOR', 'CLI_EDEMA', 'CLI_EQUIMO',\n",
        "       'CLI_NECROS', 'CLI_LOCAL_', 'CLI_LOCA_1', 'MCLI_SIST', 'CLI_NEURO',\n",
        "       'CLI_HEMORR', 'CLI_VAGAIS', 'CLI_MIOLIT', 'CLI_RENAL', 'CLI_OUTR_2',\n",
        "       'CLI_OUTR_3', 'CLI_TEMPO_', 'TP_ACIDENT', 'ANI_TIPO_1', 'ANI_SERPEN',\n",
        "       'ANI_ARANHA', 'ANI_LAGART', 'TRA_CLASSI', 'CON_SOROTE', 'NU_AMPOLAS',\n",
        "       'NU_AMPOL_1', 'NU_AMPOL_8', 'NU_AMPOL_6', 'NU_AMPOL_4', 'NU_AMPO_7',\n",
        "       'NU_AMPO_5', 'NU_AMPOL_9', 'NU_AMPOL_3', 'COM_LOC', 'COM_SECUND',\n",
        "       'COM_NECROS', 'COM_COMPOR', 'COM_DEFICT', 'COM_APUTAC', 'COM_SISTEM',\n",
        "       'COM_RENAL', 'COM_EDEMA', 'COM_SEPTIC', 'COM_CHOQUE', 'DOENCA_TRA',\n",
        "       'EVOLUCAO', 'DT_OBITO', 'DT_ENCERRA', 'DT_DIGITA']"
      ],
      "metadata": {
        "id": "Zb4WJV50BgJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, we use this list within square brackets, next to the name of our table. We can assign a new name to the table or use the same name. In the latter option, we replace our dataframe, while in the former, we create a new one."
      ],
      "metadata": {
        "id": "UUBMHy7-bLpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas = datas[columns_to_maintain].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "pAEvFMGrCnAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how it turned out"
      ],
      "metadata": {
        "id": "ZI_hXx-dcoCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas"
      ],
      "metadata": {
        "id": "R6arITGGdF0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Recoding\n",
        "One of the major issues with DBF files is the encoding of variables. Simply opening the file does not provide clear information, as we have to refer to the data dictionary of that file. With Python, we can recode the columns by writing the data dictionary for each one. It is a time-consuming task, but we only need to do it once, and then it will be ready.\n",
        "\n",
        "Upon evaluating the data dictionary, we notice that many variables have values such as YES and NO. For these cases, we will create a mini dictionary and apply the .replace function, which will replace the values found in the table with those seen in the dictionary."
      ],
      "metadata": {
        "id": "wUk-vfZLdLM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take an example column and then apply it to the others."
      ],
      "metadata": {
        "id": "9pPXkGneeuuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas['MCLI_LOCAL'] = datas['MCLI_LOCAL'].replace({1:'Sim', 2: 'Não', 9:'Ignorado'})"
      ],
      "metadata": {
        "id": "ZqLWSO9ODeEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how it turned out:"
      ],
      "metadata": {
        "id": "CkSNwyave7kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas['MCLI_LOCAL']"
      ],
      "metadata": {
        "id": "BXMfbOhyfIUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will create a list with the columns that have the values **YES** and **NO**."
      ],
      "metadata": {
        "id": "ucBWRy9XfM07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_yes_or_no_type = ['MCLI_LOCAL', 'CLI_DOR', 'CLI_EDEMA', 'CLI_EQUIMO', \n",
        "                          'CLI_NECROS', 'CLI_LOCAL_', 'MCLI_SIST', 'CLI_NEURO',\n",
        "                          'CLI_HEMORR', 'CLI_VAGAIS', 'CLI_MIOLIT', 'CLI_RENAL', \n",
        "                          'CLI_OUTR_2', 'CON_SOROTE', 'COM_LOC', 'COM_SECUND', \n",
        "                          'COM_NECROS', 'COM_COMPOR',  'COM_DEFICT', 'COM_APUTAC',\n",
        "                          'COM_SISTEM', 'COM_RENAL',  'COM_EDEMA', 'COM_SEPTIC', \n",
        "                          'COM_CHOQUE', 'DOENCA_TRA']"
      ],
      "metadata": {
        "id": "7Bub2bXPE94X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will perform a bulk change of this data. For that, we will use the **for** loop, which allows us to apply the same operation multiple times, only changing one parameter."
      ],
      "metadata": {
        "id": "kS9i8GLDf5xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in columns_yes_or_no_type:\n",
        "  datas[column] = datas[column].replace({1:'Sim', 2: 'Não', 9:'Ignorado'})\n",
        "\n",
        "datas"
      ],
      "metadata": {
        "id": "c6puliDcIlIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some fields are of the date type. Let's identify them using the **.info()** function."
      ],
      "metadata": {
        "id": "sG4s7s8ohdKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas.info()"
      ],
      "metadata": {
        "id": "Bkcs07-hKwPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the identified fields, let's now add them to a list."
      ],
      "metadata": {
        "id": "BPNexG_UiEAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_date_type = ['DT_NOTIFIC', 'DT_SIN_PRI', 'DT_INVEST', \n",
        "                     'DT_OBITO', 'DT_ENCERRA', 'DT_DIGITA', 'ANT_DT_ACI']"
      ],
      "metadata": {
        "id": "nPRbghOBKPad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, we can use the **for** loop to make changes in these fields. To convert the date type to the desired format, we should use the pandas function **.to_datetime**, where we pass the column name, the desired date format, and error handling as parameters."
      ],
      "metadata": {
        "id": "sM6-kjWIiWhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in columns_date_type:\n",
        "  datas[column] = pd.to_datetime(datas[column], format='%Y%m%d', errors='coerce')"
      ],
      "metadata": {
        "id": "K-5T7hZAMSSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check how one of the fields turned out."
      ],
      "metadata": {
        "id": "JJH8vIvSjdBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas['DT_NOTIFIC']"
      ],
      "metadata": {
        "id": "lKjcQaXrjkxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now comes the most labor-intensive part, where we have to rewrite all the codifications from the data dictionary. In other words, we will create multiple dictionaries based on the SINAN dictionary."
      ],
      "metadata": {
        "id": "Ip-coI2LjuTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ANT_TEMPO_\n",
        "datas['ANT_TEMPO_'] = datas['ANT_TEMPO_'].replace({1: '0 - 1h',\n",
        "                                                   2: '1 - 3h',\n",
        "                                                   3: '3 - 6h',\n",
        "                                                   4: '6 - 12h',\n",
        "                                                   5: '12 e 24h',\n",
        "                                                   6: '24 e +h',\n",
        "                                                   9: 'Ignorado'})\n",
        "\n",
        "# ANT_LOCA_1\n",
        "datas['ANT_LOCA_1'] = datas['ANT_LOCA_1'].replace({1: 'Cabeça',\n",
        "                                                   2: 'Braço',\n",
        "                                                   3: 'Ante-Braço',\n",
        "                                                   4: 'Mão',\n",
        "                                                   5: 'Dedo da Mão',\n",
        "                                                   6: 'Tronco',\n",
        "                                                   7: 'Coxa',\n",
        "                                                   8: 'Perna',\n",
        "                                                   9: 'Pé',\n",
        "                                                   10: 'Dedo do Pé',\n",
        "                                                   99: 'Ignorado'})\n",
        "\n",
        "# CLI_TEMPO_\n",
        "datas['CLI_TEMPO_'] = datas['CLI_TEMPO_'].replace({1: 'Normal',\n",
        "                                                   2: 'Alterado',\n",
        "                                                   9: 'Não Realizado'})\n",
        "\n",
        "# TP_ACIDENT\n",
        "datas['TP_ACIDENT'] = datas['TP_ACIDENT'].replace({1: 'Serpente',\n",
        "                                                   2: 'Aranha',\n",
        "                                                   3: 'Escorpião',\n",
        "                                                   4: 'Lagarta',\n",
        "                                                   5: 'Abelha',\n",
        "                                                   6: 'Outros',\n",
        "                                                   9: 'Ignorado'})\n",
        "\n",
        "# ANI_SERPEN\n",
        "datas['ANI_SERPEN'] = datas['ANI_SERPEN'].replace({1: 'Botrópico',\n",
        "                                                   2: 'Crotálico',\n",
        "                                                   3: 'Elapídico',\n",
        "                                                   4: 'Laquético',\n",
        "                                                   5: 'Serpente Não Peçonhenta',\n",
        "                                                   9: 'Ignorado'})\n",
        "\n",
        "# ANI_ARANHA\n",
        "datas['ANI_ARANHA'] = datas['ANI_ARANHA'].replace({1: 'Foneutrismo',\n",
        "                                                   2: 'Loxoscelismo',\n",
        "                                                   3: 'Latrodectismo',\n",
        "                                                   4: 'Outra Aranha',\n",
        "                                                   9: 'Ignorado'})\n",
        "\n",
        "# ANI_LAGART\n",
        "datas['ANI_LAGART'] = datas['ANI_LAGART'].replace({1: 'Lonomia',\n",
        "                                                   2: 'Outra Lagarta',\n",
        "                                                   9: 'Ignorado'})\n",
        "\n",
        "# TRA_CLASSI\n",
        "datas['TRA_CLASSI'] = datas['TRA_CLASSI'].replace({1: 'Leve',\n",
        "                                                   2: 'Moderado',\n",
        "                                                   3: 'Grave',\n",
        "                                                   9: 'Ignorado'})\n",
        "\n",
        "# EVOLUCAO\n",
        "datas['EVOLUCAO'] = datas['EVOLUCAO'].replace({1: 'Cura',\n",
        "                                               2: 'Óbito por Acidente por Animais Peçonhentos',\n",
        "                                               3: 'Óbito por Outras Causas',\n",
        "                                               9: 'Ignorado'})\n",
        "# CS_GESTANT\n",
        "datas['CS_GESTANT'] = datas['CS_GESTANT'].replace({1: '1º Trimestre',\n",
        "                                                   2: '2º Trimestre',\n",
        "                                                   3: '3º Trimestre',\n",
        "                                                   4: 'Idade Gestacional Ignorada',\n",
        "                                                   5: 'Não',\n",
        "                                                   6: 'Não Se Aplica',\n",
        "                                                   9: 'Ignorado'})\n",
        "\n",
        "# CS_RACA\n",
        "datas['CS_RACA'] = datas['CS_RACA'].replace({1: 'Branca',\n",
        "                                             2: 'Preta',\n",
        "                                             3: 'Amarela',\n",
        "                                             4: 'Parda',\n",
        "                                             5: 'Indígena',\n",
        "                                             9: 'Ignorado'})\n",
        "\n",
        "# CS_ESCOL_N\n",
        "datas['CS_ESCOL_N'] = datas['CS_ESCOL_N'].replace({1: '1ª a 4ª Série Incompleta do EF',\n",
        "                                                   2: '4ª Série Completa do EF (antigo 1° grau)',\n",
        "                                                   3: '5ª à 8ª Série Incompleta do EF (Antigo Ginásio ou 1° grau)',\n",
        "                                                   4: 'Ensino fundamental Completo (Antigo Ginásio ou 1° grau)',\n",
        "                                                   5: 'Ensino Médio Incompleto (Antigo Colegial ou 2° grau)',\n",
        "                                                   6: 'Ensino Médio Completo (Antigo Colegial ou 2° grau)',\n",
        "                                                   7: 'Educação Superior Incompleta',\n",
        "                                                   8: 'Educação Superior Completa',\n",
        "                                                   9: 'Ignorado',\n",
        "                                                   10: 'Não se Aplica'})\n"
      ],
      "metadata": {
        "id": "mpSsUunMUCYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **AGE** column is a bit different. SINAN uses a decoding format for this column as follows: First digit:\n",
        "<br>1: Hour\n",
        "<br>2: Day\n",
        "<br>3: Month\n",
        "<br>4: Year\n",
        "\n",
        "Examples:\n",
        "<br>3009: Nine months\n",
        "<br>4018: Eighteen years\n",
        "<br>2150: 150 days\n",
        "\n",
        "Since we are only interested in age in years, we will use the following logic to convert the values in the column to years:\n",
        "\n",
        "*   If the value is greater than 4000, subtract 4000 from the age to obtain the converted value.\n",
        "*   If the age is less than 4000, assign age 0."
      ],
      "metadata": {
        "id": "BjY8gFTkkpjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ages = []\n",
        "\n",
        "for age in datas['NU_IDADE_N']:\n",
        "  if age > 4000:\n",
        "    ages.append(age - 4000)\n",
        "  else:\n",
        "    ages.append(0)\n",
        "\n",
        "datas['NU_IDADE_N'] = ages"
      ],
      "metadata": {
        "id": "YJFUOmgOkX4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IBGE code for municipality name\n",
        "\n",
        "Similarly to how we used a dictionary and the *replace* function to change elements in the DataFrame, we will do the same to transform IBGE codes into municipality names using the *map* function.\n",
        "\n",
        "Firstly, we need a table where this conversion is already prepared. You can find it here:\n",
        "https://raw.githubusercontent.com/andrejarenkow/Curso_SINAN_Udemy/main/dados/populacao%20ibge%206%20municipio%20br.csv"
      ],
      "metadata": {
        "id": "QeNF8mokoxYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a DataFrame to store this data:"
      ],
      "metadata": {
        "id": "TDq183fNrPnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "municipalities = pd.read_csv('https://raw.githubusercontent.com/andrejarenkow/Curso_SINAN_Udemy/main/dados/populacao%20ibge%206%20municipio%20br.csv')"
      ],
      "metadata": {
        "id": "jIfM9c_HmBMg"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the created table."
      ],
      "metadata": {
        "id": "at7r0SkgrgGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "municipalities"
      ],
      "metadata": {
        "id": "xiWGATgnrhA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's limit the fields of interest, just like we did before."
      ],
      "metadata": {
        "id": "sXa0a8ucsPRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_maintain = ['IBGE6', 'Municipio']\n",
        "municipalities = municipalities[columns_to_maintain]"
      ],
      "metadata": {
        "id": "7vVWvedWr4hz"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should index the IBGE6 field because it contains the code that we will use to relate to our main DataFrame. To do it we must use **.set_index()** function"
      ],
      "metadata": {
        "id": "HhiXhQxYsinV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "municipalities = municipalities.set_index('IBGE6')"
      ],
      "metadata": {
        "id": "xivxJ4y6s0xX"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a dictionary from this table so that we can use it as a basis for transforming the main DataFrame. TO do it we're gonna use the **.to_dict()** function."
      ],
      "metadata": {
        "id": "1-QsLh5ir0N-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "municipalities = municipalities.to_dict()"
      ],
      "metadata": {
        "id": "ISHkYjkBtTGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the dictionary to make sure everything is correct."
      ],
      "metadata": {
        "id": "B8JehOoSuTR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "municipalities"
      ],
      "metadata": {
        "id": "G_RwWLLNuXGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, there is a dictionary within another dictionary. To resolve this, we just need to pass the name of the inner dictionary as a parameter when creating the dictionary."
      ],
      "metadata": {
        "id": "YA7QKmnHugm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "municipalities = municipalities.to_dict()['Municipio']"
      ],
      "metadata": {
        "id": "QoTSR0kJvQ-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To transform the data, we will use the .map function. The .map function is a function that, if the value is not found in the dictionary, it will be transformed into NaN, resulting in a loss of that data. However, it is 60 times faster than the .replace function, so we save time, especially considering that we are working with a dictionary with more than 5000 values.\n",
        "\n",
        "Thus, we can convert the 3 columns that contain IBGE municipality codes (ID_MUNICIP, ID_MN_RESI, ANT_MUNIC_) using the dictionaries."
      ],
      "metadata": {
        "id": "aA8r1ov6rAvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas['ID_MUNICIP_NOME'] = datas['ID_MUNICIP'].map(municipalities)\n",
        "datas['ID_MN_RESI_NOME'] = datas['ID_MN_RESI'].map(municipalities)\n",
        "datas['ANT_MUNIC_NOME'] = datas['ANT_MUNIC_'].map(municipalities)"
      ],
      "metadata": {
        "id": "-VV_5HVXojlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the same way, it is possible to change the encoding of the OCCUPATION column. Here is the link that provides access to the occupation data: https://raw.githubusercontent.com/andrejarenkow/Curso_SINAN_Udemy/main/dados/CBO2002%20-%20Ocupacao.csv"
      ],
      "metadata": {
        "id": "yy2wFJ4Iyahx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ocupations = pd.read_csv('https://raw.githubusercontent.com/andrejarenkow/Curso_SINAN_Udemy/main/dados/CBO2002%20-%20Ocupacao.csv')\n",
        "ocupations = ocupations.set_index('CODIGO')\n",
        "ocupations = ocupations.to_dict()['TITULO']"
      ],
      "metadata": {
        "id": "EhOII3nYylm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert the column that represents occupation using IDs."
      ],
      "metadata": {
        "id": "swkL6c9k5vZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas['ID_OCUPA_N_NOME'] = datas['ID_OCUPA_N'].map(ocupations)"
      ],
      "metadata": {
        "id": "tJlPCUACzYPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To conclude, let's modify the encoding of the Federative Unit to its respective abbreviation, as we did previously. Here is the link that provides access to the federative units data: https://raw.githubusercontent.com/andrejarenkow/Curso_SINAN_Udemy/main/dados/cod_uf.csv"
      ],
      "metadata": {
        "id": "qP6jKvBG6NZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "federative_units = pd.read_csv('https://raw.githubusercontent.com/andrejarenkow/Curso_SINAN_Udemy/main/dados/cod_uf.csv')\n",
        "federative_units = federative_units.set_index('Código UF')\n",
        "federative_units = federative_units.to_dict()['UF']"
      ],
      "metadata": {
        "id": "jYVFRdC2z-yX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert the column that represents federative units using IDs.\n"
      ],
      "metadata": {
        "id": "kqrTmlnt7Oxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas['SG_UF_NOME'] = datas['SG_UF'].map(federative_units)\n",
        "datas['SG_UF_NOT_NOME'] = datas['SG_UF_NOT'].map(federative_units)\n",
        "datas['ANT_UF_NOME'] = datas['ANT_UF'].map(federative_units)"
      ],
      "metadata": {
        "id": "28lJtG_h2sOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Renaming Columns\n",
        "Another common issue we often encounter when visualizing a SINAN DBF file is the column names, which are encoded differently. Therefore, we will rename them using a function similar to what we did before."
      ],
      "metadata": {
        "id": "JtsSHLS67WlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's collect the names of all the columns"
      ],
      "metadata": {
        "id": "ZupPuqxq9gyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnhH5h-a906G",
        "outputId": "3bc69b89-c6f4-4e7e-b20f-3aaec6b93ec4"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['DT_NOTIFIC', 'SEM_NOT', 'NU_ANO', 'SG_UF_NOT', 'ID_MUNICIP',\n",
              "       'ID_REGIONA', 'DT_SIN_PRI', 'SEM_PRI', 'ANO_NASC', 'NU_IDADE_N',\n",
              "       'CS_SEXO', 'CS_GESTANT', 'CS_RACA', 'CS_ESCOL_N', 'SG_UF', 'ID_MN_RESI',\n",
              "       'ID_RG_RESI', 'ID_PAIS', 'DT_INVEST', 'ID_OCUPA_N', 'ANT_DT_ACI',\n",
              "       'ANT_UF', 'ANT_MUNIC_', 'ANT_LOCALI', 'ANT_TEMPO_', 'ANT_LOCA_1',\n",
              "       'MCLI_LOCAL', 'CLI_DOR', 'CLI_EDEMA', 'CLI_EQUIMO', 'CLI_NECROS',\n",
              "       'CLI_LOCAL_', 'CLI_LOCA_1', 'MCLI_SIST', 'CLI_NEURO', 'CLI_HEMORR',\n",
              "       'CLI_VAGAIS', 'CLI_MIOLIT', 'CLI_RENAL', 'CLI_OUTR_2', 'CLI_OUTR_3',\n",
              "       'CLI_TEMPO_', 'TP_ACIDENT', 'ANI_TIPO_1', 'ANI_SERPEN', 'ANI_ARANHA',\n",
              "       'ANI_LAGART', 'TRA_CLASSI', 'CON_SOROTE', 'NU_AMPOLAS', 'NU_AMPOL_1',\n",
              "       'NU_AMPOL_8', 'NU_AMPOL_6', 'NU_AMPOL_4', 'NU_AMPO_7', 'NU_AMPO_5',\n",
              "       'NU_AMPOL_9', 'NU_AMPOL_3', 'COM_LOC', 'COM_SECUND', 'COM_NECROS',\n",
              "       'COM_COMPOR', 'COM_DEFICT', 'COM_APUTAC', 'COM_SISTEM', 'COM_RENAL',\n",
              "       'COM_EDEMA', 'COM_SEPTIC', 'COM_CHOQUE', 'DOENCA_TRA', 'EVOLUCAO',\n",
              "       'DT_OBITO', 'DT_ENCERRA', 'DT_DIGITA', 'ID_MUNICIP_NOME',\n",
              "       'ID_MN_RESI_NOME', 'ANT_MUNICI_NOME', 'ANT_MUNIC_NOME',\n",
              "       'ID_OCUPA_N_NOME', 'SG_UF_NOME', 'SG_UF_NOT_NOME', 'ANT_UF_NOME'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's copy this list, and we'll adapt it to create a dictionary"
      ],
      "metadata": {
        "id": "sonDazRe993x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_renamed = {'DT_NOTIFIC': 'Data da Notificação', \n",
        "                   'SEM_NOT': 'Semana Epidemiológica da Notificação', \n",
        "                   'NU_ANO': 'Ano da notificação ', \n",
        "                   'SG_UF_NOT': 'UF de Notificação', \n",
        "                   'ID_MUNICIP': 'Município de Notificação',\n",
        "                   'ID_REGIONA': 'Código Regional da Notificação', \n",
        "                   'DT_SIN_PRI': 'Data dos Primeiros Sintomas / Diagnóstico', \n",
        "                   'SEM_PRI': 'Semana Epidemiológica dos Primeiros Sintomas/Diagnósticos', \n",
        "                   'ANO_NASC': 'Ano de Nascimento', \n",
        "                   'NU_IDADE_N': 'Idade',\n",
        "                   'CS_SEXO': 'Sexo', \n",
        "                   'CS_GESTANT': 'Gestação', \n",
        "                   'CS_RACA': 'Raça', \n",
        "                   'CS_ESCOL_N': 'Escolaridade', \n",
        "                   'SG_UF': 'UF', \n",
        "                   'ID_MN_RESI': 'Município de Residência',\n",
        "                   'ID_RG_RESI': 'ID Município de Residência', \n",
        "                   'ID_PAIS': 'País (Se Residente Fora do Brasil)', \n",
        "                   'DT_INVEST': 'Data da Investigação', \n",
        "                   'ID_OCUPA_N': 'Ocupação', \n",
        "                   'ANT_DT_ACI': 'Data do Acidente',\n",
        "                   'ANT_UF': 'UF', \n",
        "                   'ANT_MUNIC_': 'Município de Ocorrência do Acidente', \n",
        "                   'ANT_LOCALI': 'Localidade da Ocorrência do Acidente', \n",
        "                   'ANT_TEMPO_': 'Tempo Decorrido Picada/Atendimento', \n",
        "                   'ANT_LOCA_1': 'Local da Picada ',\n",
        "                   'MCLI_LOCAL': 'Manifestações Locais', \n",
        "                   'CLI_DOR': 'Se Manifestações Locais Sim, Especificar (Dor)', \n",
        "                   'CLI_EDEMA': 'Se Manifestações Locais Sim, Especificar (Edema)', \n",
        "                   'CLI_EQUIMO': 'Se Manifestações Locais Sim, Especificar (Equimose)', \n",
        "                   'CLI_NECROS': 'Se Manifestações Locais Sim, Especificar (Necrose)',\n",
        "                   'CLI_LOCAL_': 'Se Manifestações Locais Sim, Especificar (Outras)', \n",
        "                   'CLI_LOCA_1': 'No Caso de Outras(Especificar)', \n",
        "                   'MCLI_SIST': 'Manifestações Sistêmicas ', \n",
        "                   'CLI_NEURO': 'Se Manifestações Sistêmicas Sim, Especificar Neuroparalíticas (Ptose Palpebral, Turvação Visual)', \n",
        "                   'CLI_HEMORR': 'Se Manifestações Sistêmicas Sim, Especificar Hemorrágicas (Gengivorragia, Outros Sangramentos)',\n",
        "                   'CLI_VAGAIS': 'Se Manifestações Sistêmicas Sim, Especificar Vagais (Vômitos/Diarreia)',\n",
        "                   'CLI_MIOLIT': 'Se Manifestações Sistêmicas Sim, Especificar Miolíticas/Hemolíticas (Mialgia, Anemia, Urina Escura)',\n",
        "                   'CLI_RENAL': 'Se Manifestações Sistêmicas Sim, Especificar Renais (Oligúria/Anúria)',\n",
        "                   'CLI_OUTR_2': 'Se Manifestações Sistêmicas Sim, Especificar (Outras)',\n",
        "                   'CLI_OUTR_3': 'No caso de Outras (especificar)',\n",
        "                   'CLI_TEMPO_': 'Tempo de Coagulação',\n",
        "                   'TP_ACIDENT': 'Tipo de Acidente ',\n",
        "                   'ANI_TIPO_1': 'No caso de Outros, Especificar',\n",
        "                   'ANI_SERPEN': 'Serpente - Tipo de Acidente',\n",
        "                   'ANI_ARANHA': 'Aranha - Tipo de Acidente',\n",
        "                   'ANI_LAGART': 'Lagarta - Tipo de Acidente',\n",
        "                   'TRA_CLASSI': 'Classificação do Caso',\n",
        "                   'CON_SOROTE': 'Soroterapia',\n",
        "                   'NU_AMPOLAS': 'Se Soroterapia Sim, Especificar, Número de Ampolas de Soro: Antibrotópico (SAB)',\n",
        "                   'NU_AMPOL_1': 'Se Soroterapia Sim, Especificar, Número de Ampolas de Soro: Anticrotálico (SAC)',\n",
        "                   'NU_AMPOL_8': 'Se Soroterapia Sim, Especificar, Número de Ampolas de Soro: Antiaracnídico (SAAr)', \n",
        "                   'NU_AMPOL_6': 'Se Soroterapia Sim, Especificar, Número de Ampolas de Soro: Antibrotópico - Laquético (SABL)',\n",
        "                   'NU_AMPOL_4': 'Se Soroterapia Sim, Especificar, Número de Ampolas de Soro: Antielapídico (SAEL)',\n",
        "                   'NU_AMPO_7': 'Se Soroterapia Sim, Especificar, Número de Ampolas de Soro: Antiloxoscélico (SALox)', \n",
        "                   'NU_AMPO_5': 'Se Soroterapia Sim, Especificar, Número de Ampolas de Soro: Antibrotópico - Crotálico (SABC)',\n",
        "                   'NU_AMPOL_9': 'Se Soroterapia Sim, Especificar, Número de Ampolas de Soro: Antiescorpiônico (SAEsc)', \n",
        "                   'NU_AMPOL_3': 'Se Soroterapia Sim, Especificar, Número de Ampolas de Soro: Antilonômico (SALon)', \n",
        "                   'COM_LOC': 'Complicações Locais', \n",
        "                   'COM_SECUND': 'Se Complicações Locais Sim, Especificar - Infecção Secundária', \n",
        "                   'COM_NECROS': 'Se Complicações Locais Sim, Especificar - Necrose Extensa',\n",
        "                   'COM_COMPOR': 'Se Complicações Locais Sim, Especificar - Síndrome Comportamental',\n",
        "                   'COM_DEFICT': 'Se Complicações Locais Sim, Especificar - Déficit Funcional',\n",
        "                   'COM_APUTAC': 'Se Complicações Locais Sim, Especificar - Amputação',\n",
        "                   'COM_SISTEM': 'Se Complicações Locais Sim, Especificar - Complicações Sistêmicas',\n",
        "                   'COM_RENAL': 'Se Complicações Locais Sim, Especificar - Insuficiência Renal', \n",
        "                   'COM_EDEMA': 'Se Complicações Locais Sim, Especificar - Insuficiência Respiratória/ Edema Pulmonar Agudo',\n",
        "                   'COM_SEPTIC': 'Se Complicações Locais Sim, Especificar - Septicemia',\n",
        "                   'COM_CHOQUE': 'Se Complicações Locais Sim, Especificar - Choque',\n",
        "                   'DOENCA_TRA': 'Acidente Relacionado ao Trabalho',\n",
        "                   'EVOLUCAO': 'Evolução do Caso',\n",
        "                   'DT_OBITO': 'Data do Óbito',\n",
        "                   'DT_ENCERRA': 'Data do Encerramento ',\n",
        "                   'DT_DIGITA': 'Data de Digitação ',\n",
        "                   'ID_MUNICIP_NOME': 'Nome Municipio de Notificação',\n",
        "                   'ID_MN_RESI_NOME': 'Nome Município de Residencia', \n",
        "                   'ANT_MUNIC_NOME': 'Nome Município de Ocorrência do Acidente ',\n",
        "                   'ID_OCUPA_N_NOME': 'Nome da Ocupação', \n",
        "                   'SG_UF_NOME': 'Sigla UF',\n",
        "                   'SG_UF_NOT_NOME': 'Nome UF de Notificação',\n",
        "                   'ANT_UF_NOME': 'Nome UF' \n",
        "}"
      ],
      "metadata": {
        "id": "oy767Z5f05KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the complete dictionary, we use the **.rename** command on our DataFrame, so we will have it organized in a more appropriate way."
      ],
      "metadata": {
        "id": "eWvpdQ3r-qGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = datas.rename(columns = columns_renamed)"
      ],
      "metadata": {
        "id": "yHqJt8vS_iu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export to CSV\n",
        "Let's export our final DataFrame to Excel in case there is a need to view the data in the program. This operation takes some time."
      ],
      "metadata": {
        "id": "OKzre9-s-x3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.to_csv('sus_acidente_animais_peconhentos_dados.csv', index=False, sep=';')"
      ],
      "metadata": {
        "id": "puJ1GCQW_ig4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
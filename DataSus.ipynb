{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOagxzA8SFPdqrg5fmgGlJb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Objective of the Project\n",
        "The objective of the project is to be able to open DBC files, the standard format of SINAN, and transform them into a table, converting the encodings according to the data dictionary.\n",
        "\n",
        "It will analyze notifications of accidents involving venomous animals, which are made available by DATASUS through the link https://datasus.saude.gov.br/acesso-a-informacao/doencas-e-agravos-de-notificacao-de-2007-em-diante-sinan/, where there are several databases available.\n",
        "\n",
        "At the end of the project, there will be a data transformation and analysis notebook that can be adapted for other files available from SINAN."
      ],
      "metadata": {
        "id": "qlVMXHOlL4zM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries\n",
        "After installing the library, we need to import the one we will use:\n",
        "*   Pandas: Standard library for data \n",
        "analysis in Python."
      ],
      "metadata": {
        "id": "AqRoCglUONaG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvv46-LW-Iii"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The cell below is necessary to allow us to visualize the entire table on the screen:**"
      ],
      "metadata": {
        "id": "GpnbzwFMPTGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.max_columns = None"
      ],
      "metadata": {
        "id": "E_u3qYhY_qjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Searching for and accessing the project's DBC file.\n",
        "After downloading the DBC file, we will use the TabWin program to transform the data into CSV format, which is more commonly used and easier to work with.\n",
        "\n",
        "The TabWin program can be downloaded from the following link: https://datasus.saude.gov.br/transferencia-de-arquivos/\n",
        "\n",
        "Select:\n",
        "*   Source: Applications - *TABWIN/TABNET* - Tools for data tabulation\n",
        "*   Modality: Programs\n",
        "*   File Type: *TABWIN* data tabulator for Windows\n",
        "\n",
        "Click on **Enviar** (Submit) to upload the file. Once uploaded, click on **Download**. The website will reload, and a link named \"arquivo.zip\" will be downloaded.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "55YIC5ZEPyYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Pandas library will be used to transform the CSV file into a readable table:"
      ],
      "metadata": {
        "id": "UQoNtbVcXD7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas = pd.read_csv('/ANIMBR17.csv', encoding='latin1')"
      ],
      "metadata": {
        "id": "Ssr3xupoAFES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the transformation made, you can use the following command:"
      ],
      "metadata": {
        "id": "7y0mpsHvXgTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas"
      ],
      "metadata": {
        "id": "9gJM1r9bAsii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversion Based on SINAN Data Dictionary\n",
        "In this section, we will define which columns to keep or exclude.\n",
        "\n",
        "For this task, we need to analyze the data dictionary available at the following links:\n",
        "*   Individual Notification Data:  http://portalsinan.saude.gov.br/images/documentos/Agravos/Notificacao_Individual/DIC_DADOS_NET---Notificao-Individual_rev.pdf\n",
        "*   Accidents with Venomous Animals Data:\n",
        "http://portalsinan.saude.gov.br/images/documentos/Agravos/AAP/DIC_DADOS_Animais_Pedonhentos_v5.pdf"
      ],
      "metadata": {
        "id": "5tQEYt5RYD8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the columns of the created table, you can use the command **.columns**"
      ],
      "metadata": {
        "id": "eL32REXlXvUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas.columns"
      ],
      "metadata": {
        "id": "C0a_QiIhAtlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Among the columns above, we need to choose which ones to keep and pass their names to a list."
      ],
      "metadata": {
        "id": "Id-obmShaNi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_maintain =  ['DT_NOTIFIC', 'SEM_NOT', 'NU_ANO', 'SG_UF_NOT',\n",
        "       'ID_MUNICIP', 'ID_REGIONA', 'DT_SIN_PRI', 'SEM_PRI', 'ANO_NASC',\n",
        "       'NU_IDADE_N', 'CS_SEXO', 'CS_GESTANT', 'CS_RACA', 'CS_ESCOL_N', 'SG_UF',\n",
        "       'ID_MN_RESI', 'ID_RG_RESI', 'ID_PAIS', 'DT_INVEST', 'ID_OCUPA_N',\n",
        "       'ANT_DT_ACI', 'ANT_UF', 'ANT_MUNIC_', 'ANT_LOCALI', 'ANT_TEMPO_',\n",
        "       'ANT_LOCA_1', 'MCLI_LOCAL', 'CLI_DOR', 'CLI_EDEMA', 'CLI_EQUIMO',\n",
        "       'CLI_NECROS', 'CLI_LOCAL_', 'CLI_LOCA_1', 'MCLI_SIST', 'CLI_NEURO',\n",
        "       'CLI_HEMORR', 'CLI_VAGAIS', 'CLI_MIOLIT', 'CLI_RENAL', 'CLI_OUTR_2',\n",
        "       'CLI_OUTR_3', 'CLI_TEMPO_', 'TP_ACIDENT', 'ANI_TIPO_1', 'ANI_SERPEN',\n",
        "       'ANI_ARANHA', 'ANI_LAGART', 'TRA_CLASSI', 'CON_SOROTE', 'NU_AMPOLAS',\n",
        "       'NU_AMPOL_1', 'NU_AMPOL_8', 'NU_AMPOL_6', 'NU_AMPOL_4', 'NU_AMPO_7',\n",
        "       'NU_AMPO_5', 'NU_AMPOL_9', 'NU_AMPOL_3', 'COM_LOC', 'COM_SECUND',\n",
        "       'COM_NECROS', 'COM_COMPOR', 'COM_DEFICT', 'COM_APUTAC', 'COM_SISTEM',\n",
        "       'COM_RENAL', 'COM_EDEMA', 'COM_SEPTIC', 'COM_CHOQUE', 'DOENCA_TRA',\n",
        "       'EVOLUCAO', 'DT_OBITO', 'DT_ENCERRA', 'DT_DIGITA']"
      ],
      "metadata": {
        "id": "Zb4WJV50BgJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, we use this list within square brackets, next to the name of our table. We can assign a new name to the table or use the same name. In the latter option, we replace our dataframe, while in the former, we create a new one."
      ],
      "metadata": {
        "id": "UUBMHy7-bLpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas = datas[columns_to_maintain].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "pAEvFMGrCnAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how it turned out"
      ],
      "metadata": {
        "id": "ZI_hXx-dcoCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas"
      ],
      "metadata": {
        "id": "R6arITGGdF0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Recoding\n",
        "One of the major issues with DBF files is the encoding of variables. Simply opening the file does not provide clear information, as we have to refer to the data dictionary of that file. With Python, we can recode the columns by writing the data dictionary for each one. It is a time-consuming task, but we only need to do it once, and then it will be ready.\n",
        "\n",
        "Upon evaluating the data dictionary, we notice that many variables have values such as YES and NO. For these cases, we will create a mini dictionary and apply the .replace function, which will replace the values found in the table with those seen in the dictionary."
      ],
      "metadata": {
        "id": "wUk-vfZLdLM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take an example column and then apply it to the others."
      ],
      "metadata": {
        "id": "9pPXkGneeuuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas['MCLI_LOCAL'] = datas['MCLI_LOCAL'].replace({1:'Sim', 2: 'NÃ£o', 9:'Ignorado'})"
      ],
      "metadata": {
        "id": "ZqLWSO9ODeEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how it turned out:"
      ],
      "metadata": {
        "id": "CkSNwyave7kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas['MCLI_LOCAL']"
      ],
      "metadata": {
        "id": "BXMfbOhyfIUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will create a list with the columns that have the values **YES** and **NO**."
      ],
      "metadata": {
        "id": "ucBWRy9XfM07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_yes_or_no_type = ['MCLI_LOCAL', 'CLI_DOR', 'CLI_EDEMA', 'CLI_EQUIMO', \n",
        "                          'CLI_NECROS', 'CLI_LOCAL_', 'MCLI_SIST', 'CLI_NEURO',\n",
        "                          'CLI_HEMORR', 'CLI_VAGAIS', 'CLI_MIOLIT', 'CLI_RENAL', \n",
        "                          'CLI_OUTR_2', 'CON_SOROTE', 'COM_LOC', 'COM_SECUND', \n",
        "                          'COM_NECROS', 'COM_COMPOR',  'COM_DEFICT', 'COM_APUTAC',\n",
        "                          'COM_SISTEM', 'COM_RENAL',  'COM_EDEMA', 'COM_SEPTIC', \n",
        "                          'COM_CHOQUE', 'DOENCA_TRA']"
      ],
      "metadata": {
        "id": "7Bub2bXPE94X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will perform a bulk change of this data. For that, we will use the **for** loop, which allows us to apply the same operation multiple times, only changing one parameter."
      ],
      "metadata": {
        "id": "kS9i8GLDf5xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in columns_yes_or_no_type:\n",
        "  datas[column] = datas[column].replace({1:'Sim', 2: 'NÃ£o', 9:'Ignorado'})\n",
        "\n",
        "datas"
      ],
      "metadata": {
        "id": "c6puliDcIlIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some fields are of the date type. Let's identify them using the **.info()** function."
      ],
      "metadata": {
        "id": "sG4s7s8ohdKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas.info()"
      ],
      "metadata": {
        "id": "Bkcs07-hKwPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the identified fields, let's now add them to a list."
      ],
      "metadata": {
        "id": "BPNexG_UiEAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_date_type = ['DT_NOTIFIC', 'DT_SIN_PRI', 'DT_INVEST', \n",
        "                     'DT_OBITO', 'DT_ENCERRA', 'DT_DIGITA', 'ANT_DT_ACI']"
      ],
      "metadata": {
        "id": "nPRbghOBKPad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, we can use the **for** loop to make changes in these fields. To convert the date type to the desired format, we should use the pandas function **.to_datetime**, where we pass the column name, the desired date format, and error handling as parameters."
      ],
      "metadata": {
        "id": "sM6-kjWIiWhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in columns_date_type:\n",
        "  datas[column] = pd.to_datetime(datas[column], format='%Y%m%d', errors='coerce')"
      ],
      "metadata": {
        "id": "K-5T7hZAMSSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check how one of the fields turned out."
      ],
      "metadata": {
        "id": "JJH8vIvSjdBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas['DT_NOTIFIC']"
      ],
      "metadata": {
        "id": "lKjcQaXrjkxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now comes the most labor-intensive part, where we have to rewrite all the codifications from the data dictionary. In other words, we will create multiple dictionaries based on the SINAN dictionary."
      ],
      "metadata": {
        "id": "Ip-coI2LjuTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ANT_TEMPO_\n",
        "datas['ANT_TEMPO_'] = datas['ANT_TEMPO_'].replace({1: '0 - 1h',\n",
        "                                                   2: '1 - 3h',\n",
        "                                                   3: '3 - 6h',\n",
        "                                                   4: '6 - 12h',\n",
        "                                                   5: '12 e 24h',\n",
        "                                                   6: '24 e +h',\n",
        "                                                   9: 'Ignorado'})\n",
        "\n",
        "# ANT_LOCA_1\n",
        "datas['ANT_LOCA_1'] = datas['ANT_LOCA_1'].replace({1: 'CabeÃ§a',\n",
        "                                                   2: 'BraÃ§o',\n",
        "                                                   3: 'Ante-BraÃ§o',\n",
        "                                                   4: 'MÃ£o',\n",
        "                                                   5: 'Dedo da MÃ£o',\n",
        "                                                   6: 'Tronco',\n",
        "                                                   7: 'Coxa',\n",
        "                                                   8: 'Perna',\n",
        "                                                   9: 'PÃ©',\n",
        "                                                   10: 'Dedo do PÃ©',\n",
        "                                                   99: 'Ignorado'})\n",
        "\n",
        "# CLI_TEMPO_\n",
        "datas['CLI_TEMPO_'] = datas['CLI_TEMPO_'].replace({1: 'Normal',\n",
        "                                                   2: 'Alterado',\n",
        "                                                   9: 'NÃ£o Realizado'})\n",
        "\n",
        "# TP_ACIDENT\n",
        "datas['TP_ACIDENT'] = datas['TP_ACIDENT'].replace({1: 'Serpente',\n",
        "                                                   2: 'Aranha',\n",
        "                                                   3: 'EscorpiÃ£o',\n",
        "                                                   4: 'Lagarta',\n",
        "                                                   5: 'Abelha',\n",
        "                                                   6: 'Outros',\n",
        "                                                   9: 'Ignorado'})\n",
        "\n",
        "# ANI_SERPEN\n",
        "datas['ANI_SERPEN'] = datas['ANI_SERPEN'].replace({1: 'BotrÃ³pico',\n",
        "                                                   2: 'CrotÃ¡lico',\n",
        "                                                   3: 'ElapÃ­dico',\n",
        "                                                   4: 'LaquÃ©tico',\n",
        "                                                   5: 'Serpente NÃ£o PeÃ§onhenta',\n",
        "                                                   9: 'Ignorado'})\n",
        "\n",
        "# ANI_ARANHA\n",
        "datas['ANI_ARANHA'] = datas['ANI_ARANHA'].replace({1: 'Foneutrismo',\n",
        "                                                   2: 'Loxoscelismo',\n",
        "                                                   3: 'Latrodectismo',\n",
        "                                                   4: 'Outra Aranha',\n",
        "                                                   9: 'Ignorado'})\n",
        "\n",
        "# ANI_LAGART\n",
        "datas['ANI_LAGART'] = datas['ANI_LAGART'].replace({1: 'Lonomia',\n",
        "                                                   2: 'Outra Lagarta',\n",
        "                                                   9: 'Ignorado'})\n",
        "\n",
        "# TRA_CLASSI\n",
        "datas['TRA_CLASSI'] = datas['TRA_CLASSI'].replace({1: 'Leve',\n",
        "                                                   2: 'Moderado',\n",
        "                                                   3: 'Grave',\n",
        "                                                   9: 'Ignorado'})\n",
        "\n",
        "# EVOLUCAO\n",
        "datas['EVOLUCAO'] = datas['EVOLUCAO'].replace({1: 'Cura',\n",
        "                                               2: 'Ãbito por Acidente por Animais PeÃ§onhentos',\n",
        "                                               3: 'Ãbito por Outras Causas',\n",
        "                                               9: 'Ignorado'})\n",
        "# CS_GESTANT\n",
        "datas['CS_GESTANT'] = datas['CS_GESTANT'].replace({1: '1Âº Trimestre',\n",
        "                                                   2: '2Âº Trimestre',\n",
        "                                                   3: '3Âº Trimestre',\n",
        "                                                   4: 'Idade Gestacional Ignorada',\n",
        "                                                   5: 'NÃ£o',\n",
        "                                                   6: 'NÃ£o Se Aplica',\n",
        "                                                   9: 'Ignorado'})\n",
        "\n",
        "# CS_RACA\n",
        "datas['CS_RACA'] = datas['CS_RACA'].replace({1: 'Branca',\n",
        "                                             2: 'Preta',\n",
        "                                             3: 'Amarela',\n",
        "                                             4: 'Parda',\n",
        "                                             5: 'IndÃ­gena',\n",
        "                                             9: 'Ignorado'})\n",
        "\n",
        "# CS_ESCOL_N\n",
        "datas['CS_ESCOL_N'] = datas['CS_ESCOL_N'].replace({1: '1Âª a 4Âª SÃ©rie Incompleta do EF',\n",
        "                                                   2: '4Âª SÃ©rie Completa do EF (antigo 1Â° grau)',\n",
        "                                                   3: '5Âª Ã  8Âª SÃ©rie Incompleta do EF (Antigo GinÃ¡sio ou 1Â° grau)',\n",
        "                                                   4: 'Ensino fundamental Completo (Antigo GinÃ¡sio ou 1Â° grau)',\n",
        "                                                   5: 'Ensino MÃ©dio Incompleto (Antigo Colegial ou 2Â° grau)',\n",
        "                                                   6: 'Ensino MÃ©dio Completo (Antigo Colegial ou 2Â° grau)',\n",
        "                                                   7: 'EducaÃ§Ã£o Superior Incompleta',\n",
        "                                                   8: 'EducaÃ§Ã£o Superior Completa',\n",
        "                                                   9: 'Ignorado',\n",
        "                                                   10: 'NÃ£o se Aplica'})\n"
      ],
      "metadata": {
        "id": "mpSsUunMUCYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **AGE** column is a bit different. SINAN uses a decoding format for this column as follows: First digit:\n",
        "<br>1: Hour\n",
        "<br>2: Day\n",
        "<br>3: Month\n",
        "<br>4: Year\n",
        "\n",
        "Examples:\n",
        "<br>3009: Nine months\n",
        "<br>4018: Eighteen years\n",
        "<br>2150: 150 days\n",
        "\n",
        "Since we are only interested in age in years, we will use the following logic to convert the values in the column to years:\n",
        "\n",
        "*   If the value is greater than 4000, subtract 4000 from the age to obtain the converted value.\n",
        "*   If the age is less than 4000, assign age 0."
      ],
      "metadata": {
        "id": "BjY8gFTkkpjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ages = []\n",
        "\n",
        "for age in datas['NU_IDADE_N']:\n",
        "  if age > 4000:\n",
        "    ages.append(age - 4000)\n",
        "  else:\n",
        "    ages.append(0)\n",
        "\n",
        "datas['NU_IDADE_N'] = ages"
      ],
      "metadata": {
        "id": "YJFUOmgOkX4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IBGE code for municipality name\n",
        "\n",
        "Similarly to how we used a dictionary and the *replace* function to change elements in the DataFrame, we will do the same to transform IBGE codes into municipality names using the *map* function.\n",
        "\n",
        "Firstly, we need a table where this conversion is already prepared. You can find it here:\n",
        "https://raw.githubusercontent.com/andrejarenkow/Curso_SINAN_Udemy/main/dados/populacao%20ibge%206%20municipio%20br.csv"
      ],
      "metadata": {
        "id": "QeNF8mokoxYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a DataFrame to store this data:"
      ],
      "metadata": {
        "id": "TDq183fNrPnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "municipalities = pd.read_csv('https://raw.githubusercontent.com/andrejarenkow/Curso_SINAN_Udemy/main/dados/populacao%20ibge%206%20municipio%20br.csv')"
      ],
      "metadata": {
        "id": "jIfM9c_HmBMg"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the created table."
      ],
      "metadata": {
        "id": "at7r0SkgrgGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "municipalities"
      ],
      "metadata": {
        "id": "xiWGATgnrhA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's limit the fields of interest, just like we did before."
      ],
      "metadata": {
        "id": "sXa0a8ucsPRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_maintain = ['IBGE6', 'Municipio']\n",
        "municipalities = municipalities[columns_to_maintain]"
      ],
      "metadata": {
        "id": "7vVWvedWr4hz"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should index the IBGE6 field because it contains the code that we will use to relate to our main DataFrame. To do it we must use **.set_index()** function"
      ],
      "metadata": {
        "id": "HhiXhQxYsinV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "municipalities = municipalities.set_index('IBGE6')"
      ],
      "metadata": {
        "id": "xivxJ4y6s0xX"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a dictionary from this table so that we can use it as a basis for transforming the main DataFrame. TO do it we're gonna use the **.to_dict()** function."
      ],
      "metadata": {
        "id": "1-QsLh5ir0N-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "municipalities = municipalities.to_dict()"
      ],
      "metadata": {
        "id": "ISHkYjkBtTGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the dictionary to make sure everything is correct."
      ],
      "metadata": {
        "id": "B8JehOoSuTR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "municipalities"
      ],
      "metadata": {
        "id": "G_RwWLLNuXGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, there is a dictionary within another dictionary. To resolve this, we just need to pass the name of the inner dictionary as a parameter when creating the dictionary."
      ],
      "metadata": {
        "id": "YA7QKmnHugm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "municipalities = municipalities.to_dict()['Municipio']"
      ],
      "metadata": {
        "id": "QoTSR0kJvQ-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To transform the data, we will use the .map function. The .map function is a function that, if the value is not found in the dictionary, it will be transformed into NaN, resulting in a loss of that data. However, it is 60 times faster than the .replace function, so we save time, especially considering that we are working with a dictionary with more than 5000 values.\n",
        "\n",
        "Thus, we can convert the 3 columns that contain IBGE municipality codes (ID_MUNICIP, ID_MN_RESI, ANT_MUNIC_) using the dictionaries."
      ],
      "metadata": {
        "id": "aA8r1ov6rAvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas['ID_MUNICIP_NOME'] = datas['ID_MUNICIP'].map(municipalities)\n",
        "datas['ID_MN_RESI_NOME'] = datas['ID_MN_RESI'].map(municipalities)\n",
        "datas['ANT_MUNIC_NOME'] = datas['ANT_MUNIC_'].map(municipalities)"
      ],
      "metadata": {
        "id": "-VV_5HVXojlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the same way, it is possible to change the encoding of the OCCUPATION column. Here is the link that provides access to the occupation data: https://raw.githubusercontent.com/andrejarenkow/Curso_SINAN_Udemy/main/dados/CBO2002%20-%20Ocupacao.csv"
      ],
      "metadata": {
        "id": "yy2wFJ4Iyahx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ocupations = pd.read_csv('https://raw.githubusercontent.com/andrejarenkow/Curso_SINAN_Udemy/main/dados/CBO2002%20-%20Ocupacao.csv')\n",
        "ocupations = ocupations.set_index('CODIGO')\n",
        "ocupations = ocupations.to_dict()['TITULO']"
      ],
      "metadata": {
        "id": "EhOII3nYylm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert the column that represents occupation using IDs."
      ],
      "metadata": {
        "id": "swkL6c9k5vZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas['ID_OCUPA_N_NOME'] = datas['ID_OCUPA_N'].map(ocupations)"
      ],
      "metadata": {
        "id": "tJlPCUACzYPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To conclude, let's modify the encoding of the Federative Unit to its respective abbreviation, as we did previously. Here is the link that provides access to the federative units data: https://raw.githubusercontent.com/andrejarenkow/Curso_SINAN_Udemy/main/dados/cod_uf.csv"
      ],
      "metadata": {
        "id": "qP6jKvBG6NZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "federative_units = pd.read_csv('https://raw.githubusercontent.com/andrejarenkow/Curso_SINAN_Udemy/main/dados/cod_uf.csv')\n",
        "federative_units = federative_units.set_index('CÃ³digo UF')\n",
        "federative_units = federative_units.to_dict()['UF']"
      ],
      "metadata": {
        "id": "jYVFRdC2z-yX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert the column that represents federative units using IDs.\n"
      ],
      "metadata": {
        "id": "kqrTmlnt7Oxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas['SG_UF_NOME'] = datas['SG_UF'].map(federative_units)\n",
        "datas['SG_UF_NOT_NOME'] = datas['SG_UF_NOT'].map(federative_units)\n",
        "datas['ANT_UF_NOME'] = datas['ANT_UF'].map(federative_units)"
      ],
      "metadata": {
        "id": "28lJtG_h2sOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Renaming Columns\n",
        "Another common issue we often encounter when visualizing a SINAN DBF file is the column names, which are encoded differently. Therefore, we will rename them using a function similar to what we did before."
      ],
      "metadata": {
        "id": "JtsSHLS67WlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's collect the names of all the columns"
      ],
      "metadata": {
        "id": "ZupPuqxq9gyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnhH5h-a906G",
        "outputId": "3bc69b89-c6f4-4e7e-b20f-3aaec6b93ec4"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['DT_NOTIFIC', 'SEM_NOT', 'NU_ANO', 'SG_UF_NOT', 'ID_MUNICIP',\n",
              "       'ID_REGIONA', 'DT_SIN_PRI', 'SEM_PRI', 'ANO_NASC', 'NU_IDADE_N',\n",
              "       'CS_SEXO', 'CS_GESTANT', 'CS_RACA', 'CS_ESCOL_N', 'SG_UF', 'ID_MN_RESI',\n",
              "       'ID_RG_RESI', 'ID_PAIS', 'DT_INVEST', 'ID_OCUPA_N', 'ANT_DT_ACI',\n",
              "       'ANT_UF', 'ANT_MUNIC_', 'ANT_LOCALI', 'ANT_TEMPO_', 'ANT_LOCA_1',\n",
              "       'MCLI_LOCAL', 'CLI_DOR', 'CLI_EDEMA', 'CLI_EQUIMO', 'CLI_NECROS',\n",
              "       'CLI_LOCAL_', 'CLI_LOCA_1', 'MCLI_SIST', 'CLI_NEURO', 'CLI_HEMORR',\n",
              "       'CLI_VAGAIS', 'CLI_MIOLIT', 'CLI_RENAL', 'CLI_OUTR_2', 'CLI_OUTR_3',\n",
              "       'CLI_TEMPO_', 'TP_ACIDENT', 'ANI_TIPO_1', 'ANI_SERPEN', 'ANI_ARANHA',\n",
              "       'ANI_LAGART', 'TRA_CLASSI', 'CON_SOROTE', 'NU_AMPOLAS', 'NU_AMPOL_1',\n",
              "       'NU_AMPOL_8', 'NU_AMPOL_6', 'NU_AMPOL_4', 'NU_AMPO_7', 'NU_AMPO_5',\n",
              "       'NU_AMPOL_9', 'NU_AMPOL_3', 'COM_LOC', 'COM_SECUND', 'COM_NECROS',\n",
              "       'COM_COMPOR', 'COM_DEFICT', 'COM_APUTAC', 'COM_SISTEM', 'COM_RENAL',\n",
              "       'COM_EDEMA', 'COM_SEPTIC', 'COM_CHOQUE', 'DOENCA_TRA', 'EVOLUCAO',\n",
              "       'DT_OBITO', 'DT_ENCERRA', 'DT_DIGITA', 'ID_MUNICIP_NOME',\n",
              "       'ID_MN_RESI_NOME', 'ANT_MUNICI_NOME', 'ANT_MUNIC_NOME',\n",
              "       'ID_OCUPA_N_NOME', 'SG_UF_NOME', 'SG_UF_NOT_NOME', 'ANT_UF_NOME'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's copy this list, and we'll adapt it to create a dictionary"
      ],
      "metadata": {
        "id": "sonDazRe993x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_renamed = {'DT_NOTIFIC': 'Data da NotificaÃ§Ã£o', \n",
        "                   'SEM_NOT': 'Semana EpidemiolÃ³gica da NotificaÃ§Ã£o', \n",
        "                   'NU_ANO': 'Ano da notificaÃ§Ã£o ', \n",
        "                   'SG_UF_NOT': 'UF de NotificaÃ§Ã£o', \n",
        "                   'ID_MUNICIP': 'MunicÃ­pio de NotificaÃ§Ã£o',\n",
        "                   'ID_REGIONA': 'CÃ³digo Regional da NotificaÃ§Ã£o', \n",
        "                   'DT_SIN_PRI': 'Data dos Primeiros Sintomas / DiagnÃ³stico', \n",
        "                   'SEM_PRI': 'Semana EpidemiolÃ³gica dos Primeiros Sintomas/DiagnÃ³sticos', \n",
        "                   'ANO_NASC': 'Ano de Nascimento', \n",
        "                   'NU_IDADE_N': 'Idade',\n",
        "                   'CS_SEXO': 'Sexo', \n",
        "                   'CS_GESTANT': 'GestaÃ§Ã£o', \n",
        "                   'CS_RACA': 'RaÃ§a', \n",
        "                   'CS_ESCOL_N': 'Escolaridade', \n",
        "                   'SG_UF': 'UF', \n",
        "                   'ID_MN_RESI': 'MunicÃ­pio de ResidÃªncia',\n",
        "                   'ID_RG_RESI': 'ID MunicÃ­pio de ResidÃªncia', \n",
        "                   'ID_PAIS': 'PaÃ­s (Se Residente Fora do Brasil)', \n",
        "                   'DT_INVEST': 'Data da InvestigaÃ§Ã£o', \n",
        "                   'ID_OCUPA_N': 'OcupaÃ§Ã£o', \n",
        "                   'ANT_DT_ACI': 'Data do Acidente',\n",
        "                   'ANT_UF': 'UF', \n",
        "                   'ANT_MUNIC_': 'MunicÃ­pio de OcorrÃªncia do Acidente', \n",
        "                   'ANT_LOCALI': 'Localidade da OcorrÃªncia do Acidente', \n",
        "                   'ANT_TEMPO_': 'Tempo Decorrido Picada/Atendimento', \n",
        "                   'ANT_LOCA_1': 'Local da Picada ',\n",
        "                   'MCLI_LOCAL': 'ManifestaÃ§Ãµes Locais', \n",
        "                   'CLI_DOR': 'Se ManifestaÃ§Ãµes Locais Sim, Especificar (Dor)', \n",
        "                   'CLI_EDEMA': 'Se ManifestaÃ§Ãµes Locais Sim, Especificar (Edema)', \n",
        "                   'CLI_EQUIMO': 'Se ManifestaÃ§Ãµes Locais Sim, Especificar (Equimose)', \n",
        "                   'CLI_NECROS': 'Se ManifestaÃ§Ãµes Locais Sim, Especificar (Necrose)',\n",
        "                   'CLI_LOCAL_': 'Se ManifestaÃ§Ãµes Locais Sim, Especificar (Outras)', \n",
        "                   'CLI_LOCA_1': 'No Caso de Outras(Especificar)', \n",
        "                   'MCLI_SIST': 'ManifestaÃ§Ãµes SistÃªmicas ', \n",
        "                   'CLI_NEURO': 'Se ManifestaÃ§Ãµes SistÃªmicas Sim, Especificar NeuroparalÃ­ticas (Ptose Palpebral, TurvaÃ§Ã£o Visual)', \n",
        "                   'CLI_HEMORR': 'Se ManifestaÃ§Ãµes SistÃªmicas Sim, Especificar HemorrÃ¡gicas (Gengivorragia, Outros Sangramentos)',\n",
        "                   'CLI_VAGAIS': 'Se ManifestaÃ§Ãµes SistÃªmicas Sim, Especificar Vagais (VÃ´mitos/Diarreia)',\n",
        "                   'CLI_MIOLIT': 'Se ManifestaÃ§Ãµes SistÃªmicas Sim, Especificar MiolÃ­ticas/HemolÃ­ticas (Mialgia, Anemia, Urina Escura)',\n",
        "                   'CLI_RENAL': 'Se ManifestaÃ§Ãµes SistÃªmicas Sim, Especificar Renais (OligÃºria/AnÃºria)',\n",
        "                   'CLI_OUTR_2': 'Se ManifestaÃ§Ãµes SistÃªmicas Sim, Especificar (Outras)',\n",
        "                   'CLI_OUTR_3': 'No caso de Outras (especificar)',\n",
        "                   'CLI_TEMPO_': 'Tempo de CoagulaÃ§Ã£o',\n",
        "                   'TP_ACIDENT': 'Tipo de Acidente ',\n",
        "                   'ANI_TIPO_1': 'No caso de Outros, Especificar',\n",
        "                   'ANI_SERPEN': 'Serpente - Tipo de Acidente',\n",
        "                   'ANI_ARANHA': 'Aranha - Tipo de Acidente',\n",
        "                   'ANI_LAGART': 'Lagarta - Tipo de Acidente',\n",
        "                   'TRA_CLASSI': 'ClassificaÃ§Ã£o do Caso',\n",
        "                   'CON_SOROTE': 'Soroterapia',\n",
        "                   'NU_AMPOLAS': 'Se Soroterapia Sim, Especificar, NÃºmero de Ampolas de Soro: AntibrotÃ³pico (SAB)',\n",
        "                   'NU_AMPOL_1': 'Se Soroterapia Sim, Especificar, NÃºmero de Ampolas de Soro: AnticrotÃ¡lico (SAC)',\n",
        "                   'NU_AMPOL_8': 'Se Soroterapia Sim, Especificar, NÃºmero de Ampolas de Soro: AntiaracnÃ­dico (SAAr)', \n",
        "                   'NU_AMPOL_6': 'Se Soroterapia Sim, Especificar, NÃºmero de Ampolas de Soro: AntibrotÃ³pico - LaquÃ©tico (SABL)',\n",
        "                   'NU_AMPOL_4': 'Se Soroterapia Sim, Especificar, NÃºmero de Ampolas de Soro: AntielapÃ­dico (SAEL)',\n",
        "                   'NU_AMPO_7': 'Se Soroterapia Sim, Especificar, NÃºmero de Ampolas de Soro: AntiloxoscÃ©lico (SALox)', \n",
        "                   'NU_AMPO_5': 'Se Soroterapia Sim, Especificar, NÃºmero de Ampolas de Soro: AntibrotÃ³pico - CrotÃ¡lico (SABC)',\n",
        "                   'NU_AMPOL_9': 'Se Soroterapia Sim, Especificar, NÃºmero de Ampolas de Soro: AntiescorpiÃ´nico (SAEsc)', \n",
        "                   'NU_AMPOL_3': 'Se Soroterapia Sim, Especificar, NÃºmero de Ampolas de Soro: AntilonÃ´mico (SALon)', \n",
        "                   'COM_LOC': 'ComplicaÃ§Ãµes Locais', \n",
        "                   'COM_SECUND': 'Se ComplicaÃ§Ãµes Locais Sim, Especificar - InfecÃ§Ã£o SecundÃ¡ria', \n",
        "                   'COM_NECROS': 'Se ComplicaÃ§Ãµes Locais Sim, Especificar - Necrose Extensa',\n",
        "                   'COM_COMPOR': 'Se ComplicaÃ§Ãµes Locais Sim, Especificar - SÃ­ndrome Comportamental',\n",
        "                   'COM_DEFICT': 'Se ComplicaÃ§Ãµes Locais Sim, Especificar - DÃ©ficit Funcional',\n",
        "                   'COM_APUTAC': 'Se ComplicaÃ§Ãµes Locais Sim, Especificar - AmputaÃ§Ã£o',\n",
        "                   'COM_SISTEM': 'Se ComplicaÃ§Ãµes Locais Sim, Especificar - ComplicaÃ§Ãµes SistÃªmicas',\n",
        "                   'COM_RENAL': 'Se ComplicaÃ§Ãµes Locais Sim, Especificar - InsuficiÃªncia Renal', \n",
        "                   'COM_EDEMA': 'Se ComplicaÃ§Ãµes Locais Sim, Especificar - InsuficiÃªncia RespiratÃ³ria/ Edema Pulmonar Agudo',\n",
        "                   'COM_SEPTIC': 'Se ComplicaÃ§Ãµes Locais Sim, Especificar - Septicemia',\n",
        "                   'COM_CHOQUE': 'Se ComplicaÃ§Ãµes Locais Sim, Especificar - Choque',\n",
        "                   'DOENCA_TRA': 'Acidente Relacionado ao Trabalho',\n",
        "                   'EVOLUCAO': 'EvoluÃ§Ã£o do Caso',\n",
        "                   'DT_OBITO': 'Data do Ãbito',\n",
        "                   'DT_ENCERRA': 'Data do Encerramento ',\n",
        "                   'DT_DIGITA': 'Data de DigitaÃ§Ã£o ',\n",
        "                   'ID_MUNICIP_NOME': 'Nome Municipio de NotificaÃ§Ã£o',\n",
        "                   'ID_MN_RESI_NOME': 'Nome MunicÃ­pio de Residencia', \n",
        "                   'ANT_MUNIC_NOME': 'Nome MunicÃ­pio de OcorrÃªncia do Acidente ',\n",
        "                   'ID_OCUPA_N_NOME': 'Nome da OcupaÃ§Ã£o', \n",
        "                   'SG_UF_NOME': 'Sigla UF',\n",
        "                   'SG_UF_NOT_NOME': 'Nome UF de NotificaÃ§Ã£o',\n",
        "                   'ANT_UF_NOME': 'Nome UF' \n",
        "}"
      ],
      "metadata": {
        "id": "oy767Z5f05KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the complete dictionary, we use the **.rename** command on our DataFrame, so we will have it organized in a more appropriate way."
      ],
      "metadata": {
        "id": "eWvpdQ3r-qGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = datas.rename(columns = columns_renamed)"
      ],
      "metadata": {
        "id": "yHqJt8vS_iu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export to CSV\n",
        "Let's export our final DataFrame to Excel in case there is a need to view the data in the program. This operation takes some time."
      ],
      "metadata": {
        "id": "OKzre9-s-x3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.to_csv('sus_acidente_animais_peconhentos_dados.csv', index=False, sep=';')"
      ],
      "metadata": {
        "id": "puJ1GCQW_ig4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}